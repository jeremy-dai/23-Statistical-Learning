{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Classification\n",
    "Goal: compare the Naive Bayes (NB) model to Logistic Regression (LR) on data with categorical attributes. \n",
    "- train/fit an NB and an LR model on the [Car Evaluation data set](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) \n",
    "- compare their performance by looking how well they predict in terms of 0/1-loss (misclassification rate, error percentage) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "### sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '../data/car.data.txt'\n",
    "myfile = open(file, 'r') \n",
    "mydata = []\n",
    "for line in myfile:\n",
    "    row = line.strip().split(',') \n",
    "    if row[6] == 'unacc':\n",
    "        row[6] = 'Negative'\n",
    "    else:\n",
    "        row[6] = 'Positive' \n",
    "    mydata.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attr = ['buying','maint','doors','persons','lug_boot','safety','outcome']\n",
    "df = pd.DataFrame(mydata, columns= attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying ['vhigh' 'high' 'med' 'low']\n",
      "maint ['vhigh' 'high' 'med' 'low']\n",
      "doors ['2' '3' '4' '5more']\n",
      "persons ['2' '4' 'more']\n",
      "lug_boot ['small' 'med' 'big']\n",
      "safety ['low' 'med' 'high']\n",
      "outcome ['Negative' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col,df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = int(df.shape[0]/2) # train/test size\n",
    "q = int(df.shape[1]-1) # num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## results dataframe\n",
    "models = ['NB_1','NB_0.1','NB_10','LG_full','LG_2','LG_full_l2']\n",
    "results = pd.DataFrame(0, index=np.arange(1,n+1), columns=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes maximum likelihood estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_NB(X_train, X_test, y_train, y_test, a):\n",
    "    nb = CategoricalNB(alpha = a)\n",
    "    y_pred = nb.fit(X_train, y_train).predict(X_test)\n",
    "    loss = (y_test!= y_pred).sum()/n\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression conditional likelihood maximization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LG(X_train, X_test, y_train, y_test, col = q, p='none'):\n",
    "    X_train = X_train[:,0:col]\n",
    "    X_test = X_test[:,0:col]\n",
    "    lg = LogisticRegression(random_state=2019, penalty = p) # not use regularization.\n",
    "    y_pred = lg.fit(X_train, y_train).predict(X_test)\n",
    "    loss = (y_test!= y_pred).sum()/n\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_once():\n",
    "    results = pd.DataFrame(np.nan, index=np.arange(1,n+1), columns=models)\n",
    "    for i in range(n):\n",
    "        X_tr = X_train_cat[:i+1]\n",
    "        y_tr = y_train[:i+1]\n",
    "        try:\n",
    "            results.iloc[i+1,0] = train_NB(X_tr, X_test_cat, y_tr, y_test, 1)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            results.iloc[i+1,1] = train_NB(X_tr, X_test_cat, y_tr, y_test, 0.1)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            results.iloc[i+1,2] = train_NB(X_tr, X_test_cat, y_tr, y_test, 10)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            results.iloc[i+1,3] = train_LG(X_tr, X_test_cat, y_tr, y_test, q)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            results.iloc[i+1,4] = train_LG(X_tr, X_test_cat, y_tr, y_test, 2)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            results.iloc[i+1,5] = train_LG(X_tr, X_test_cat, y_tr, y_test, q, 'l2')\n",
    "        except:\n",
    "            pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:33<06:15, 23.48s/it]"
     ]
    }
   ],
   "source": [
    "M = 20\n",
    "enc = OrdinalEncoder()\n",
    "for i in tqdm(range(M)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[attr[0:6]],df.outcome,train_size=0.5,random_state=M)\n",
    "    X_train_cat = enc.fit_transform(X_train)\n",
    "    X_test_cat = enc.transform(X_test)\n",
    "    temp = train_once()\n",
    "    results = results + temp\n",
    "results = results / M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = \"results.pkl\"\n",
    "\n",
    "with open(RESULTS, \"wb\") as dataset_outfile:\n",
    "    pickle.dump(results, dataset_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RESULTS = \"results.pkl\"\n",
    "\n",
    "with open(RESULTS, \"rb\") as dataset_infile:\n",
    "        results = pickle.load(dataset_infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16,8))\n",
    "ax.set(xscale=\"log\")\n",
    "sns.lineplot(data = results, ax=ax)\n",
    "plt.xlabel(\"Traing Data Size\")\n",
    "plt.ylabel(\"1/0 Error\")\n",
    "plt.title(\"Average 1/0 Error for models {:s} over {:d} runs. \".format(str(models),M))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
